import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import japanize_matplotlib
import seaborn as sns
import plotly.graph_objects as go
from streamlit import markdown as mkd
from sklearn.model_selection import train_test_split, cross_val_score, KFold
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_squared_error
import lightgbm as lgb
from catboost import Pool, CatBoostRegressor
from catboost import CatBoostClassifier, Pool
from dotenv import load_dotenv
import base64
import joblib

load_dotenv()
st.set_page_config(
    page_title="Draco AI",
    page_icon="ğŸ‹ï¸"
)
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Patrick+Hand&display=swap');
    h1 {
        font-family: 'Patrick Hand', sans-serif;
        color: #6699cc;
        font-weight: bold;
    }
    </style>
""", unsafe_allow_html=True)

st.markdown('<h1>Draco AIğŸª¬</h1>', unsafe_allow_html=True)

def load_image(image_path):
    with open(image_path, "rb") as img_file:
        return base64.b64encode(img_file.read()).decode()

image_path = "ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2024-06-07 17.57.16.png"  # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š
image_base64 = load_image(image_path)
st.markdown(
    f"""
    <div style="text-align: center;">
        <img src="data:image/png;base64,{image_base64}" alt="ç­‹ãƒˆãƒ¬" style="width: 100%;"/>
    </div>
    """,
    unsafe_allow_html=True
)

with st.expander("Draco AIã®èª¬æ˜ã¨ä½¿ã„æ–¹ã‚’è¡¨ç¤º"):
    st.markdown("""
        ã“ã®ã‚¢ãƒ—ãƒªã¯ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
        ä»¥ä¸‹ã®æ‰‹é †ã«å¾“ã£ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

        1. åˆ†æã«ä½¿ç”¨ã—ãŸã„CSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
        2. ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦å¯è¦–åŒ–ã‚’è¡Œã„ã¾ã™ã€‚
        3. èª¬æ˜å¤‰æ•°ã¨ç›®çš„å¤‰æ•°ã‚’é¸æŠã—ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ–¹æ³•ã‚’é¸ã³ã¾ã™ã€‚
        4. ä½¿ç”¨ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚
        5. çµæœã‚’ç¢ºèªã—ã€äºˆæ¸¬ã¨å®Ÿéš›ã®å€¤ã®ã‚°ãƒ©ãƒ•ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚
        6. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦å†äºˆæ¸¬ã™ã‚‹å ´åˆã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚
    """)

st.markdown("#### æ©Ÿæ¢°å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹CSVã¾ãŸã¯Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
uploaded_files = st.file_uploader("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv', 'xlsx'], accept_multiple_files=False)

def preprocess_data(df, ex, ob, encoding_type):
    original_ex = df[ex].copy()  # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
    df_ex = df[ex].copy()
    df_ob = df[ob].copy()

    if encoding_type == "Label Encoding":
        label_encoders = {}
        for column in df_ex.select_dtypes(include=['object']).columns:
            label_encoders[column] = LabelEncoder()
            df_ex[column] = label_encoders[column].fit_transform(df_ex[column])
        df_ob = LabelEncoder().fit_transform(df_ob)
    elif encoding_type == "One-Hot Encoding":
        df_ex = pd.get_dummies(df_ex)
        df_ob = LabelEncoder().fit_transform(df_ob)  # ç›®çš„å¤‰æ•°ã‚‚ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹

    df_ex = df_ex.apply(pd.to_numeric, errors='coerce')
    df_ob = pd.to_numeric(df_ob, errors='coerce')
    df_ex = df_ex.fillna(df_ex.mean())
    df_ob = pd.Series(df_ob).fillna(np.mean(df_ob))  # ç›®çš„å¤‰æ•°ã‚’ã‚·ãƒªãƒ¼ã‚ºã¨ã—ã¦æ‰±ã†
    return df_ex, df_ob, original_ex

def add_prediction_to_dataframe(df, predictions, start_index, ob):
    df[f'{ob}_äºˆæ¸¬'] = np.nan
    df.loc[start_index:start_index+len(predictions)-1, f'{ob}_äºˆæ¸¬'] = predictions
    return df

def download_link(object_to_download, download_filename, download_link_text):
    if isinstance(object_to_download, pd.DataFrame):
        object_to_download = object_to_download.to_csv(index=False)
    elif isinstance(object_to_download, bytes):
        b64 = base64.b64encode(object_to_download).decode()
        return f'<a href="data:application/octet-stream;base64,{b64}" download="{download_filename}">{download_link_text}</a>'

    b64 = base64.b64encode(object_to_download.encode()).decode()
    return f'<a href="data:file/txt;base64,{b64}" download="{download_filename}">{download_link_text}</a>'

if uploaded_files:
    if uploaded_files.name.endswith('.csv'):
        df = pd.read_csv(uploaded_files)
    elif uploaded_files.name.endswith('.xlsx'):
        df = pd.read_excel(uploaded_files)
        
    df_columns = df.columns

    st.markdown("### åˆ†æ&å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
    st.dataframe(df)

    st.markdown("### å¯è¦–åŒ– 3Dãƒ—ãƒ­ãƒƒãƒˆ")
    x = st.selectbox("Xè»¸", df_columns)
    y = st.selectbox("Yè»¸", df_columns)
    z = st.selectbox("Zè»¸", df_columns, index=2) if len(df_columns) > 2 else None

    x_color = st.color_picker('Xè»¸ã®è‰²', '#636EFA')
    y_color = st.color_picker('Yè»¸ã®è‰²', '#EF553B')
    z_color = st.color_picker('Zè»¸ã®è‰²', '#00CC96') if z else None

    if z:
        fig = go.Figure(data=[go.Scatter3d(
            x=df[x],
            y=df[y],
            z=df[z],
            mode='markers',
            text=[f'{x}: {x_value}<br>{y}: {y_value}<br>{z}: {z_value}' for x_value, y_value, z_value in zip(df[x], df[y], df[z])],
            marker=dict(size=5, color=x_color)
        )])
        fig.update_layout(scene=dict(
            xaxis_title=x,
            yaxis_title=y,
            zaxis_title=z,
            xaxis=dict(color=x_color),
            yaxis=dict(color=y_color),
            zaxis=dict(color=z_color)
        ))
    else:
        fig = go.Figure(data=[go.Scatter(
            x=df[x],
            y=df[y],
            mode='markers',
            text=[f'{x}: {x_value}<br>{y}: {y_value}' for x_value, y_value in zip(df[x], df[y])],
            marker=dict(color=x_color)
        )])
        fig.update_layout(xaxis_title=x, yaxis_title=y, xaxis=dict(color=x_color), yaxis=dict(color=y_color))
    
    st.plotly_chart(fig)
    
    st.markdown("### æ•£å¸ƒå›³ã¨ç›¸é–¢ä¿‚æ•°")
    x_corr = st.selectbox("Xè»¸ï¼ˆç›¸é–¢ï¼‰", df_columns, key='x_corr')
    y_corr = st.selectbox("Yè»¸ï¼ˆç›¸é–¢ï¼‰", df_columns, key='y_corr')

    if st.button("æ•£å¸ƒå›³ã¨ç›¸é–¢ä¿‚æ•°ã‚’è¡¨ç¤º"):
        corr_coef = df[x_corr].corr(df[y_corr])
        st.write(f"ç›¸é–¢ä¿‚æ•° ({x_corr}, {y_corr}): {corr_coef:.2f}")

        fig = go.Figure(data=[go.Scatter(
            x=df[x_corr],
            y=df[y_corr],
            mode='markers'
        )])
        fig.update_layout(xaxis_title=x_corr, yaxis_title=y_corr)
        st.plotly_chart(fig)

    st.markdown("### ãƒ¢ãƒ‡ãƒªãƒ³ã‚°")
    mkd('<p style="color:orange;margin-bottom:0;">èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆâ€»å…ˆé ­ã®å¤‰æ•°ãŒXè»¸ã®ãƒ©ãƒ™ãƒ«ã¨ã—ã¦è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ï¼‰</p>', unsafe_allow_html=True)
    ex = st.multiselect("", df_columns)
    mkd('<p style="color:red;margin-bottom:0;">ç›®çš„å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„</p>', unsafe_allow_html=True)
    ob = st.selectbox("", df_columns)
    encoding_type = st.selectbox("ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„", ["Label Encoding", "One-Hot Encoding"])
    ml_menu = st.selectbox("å®Ÿæ–½ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ã®ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„",
                           ["é‡å›å¸°åˆ†æ", "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°åˆ†æ", "LightGBM", "Catboost"])

    model_filename = "trained_model.pkl"

    eval_metric = st.selectbox("è©•ä¾¡æŒ‡æ¨™ã‚’é¸æŠã—ã¦ãã ã•ã„", ["R2ã‚¹ã‚³ã‚¢", "MAPE", "MSE"])
    validation_method = st.selectbox("è©•ä¾¡æ–¹æ³•ã‚’é¸æŠã—ã¦ãã ã•ã„", ["ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆ", "äº¤å·®æ¤œè¨¼", "k-fold"])
    test_size = st.slider("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ", 0.1, 0.9, 0.3)

    def evaluate_model(model, X_train, X_test, y_train, y_test, eval_metric):
        y_pred_train = model.predict(X_train)
        y_pred_test = model.predict(X_test)
        
        if eval_metric == "R2ã‚¹ã‚³ã‚¢":
            train_score = r2_score(y_train, y_pred_train)
            test_score = r2_score(y_test, y_pred_test)
        elif eval_metric == "MAPE":
            train_score = mean_absolute_percentage_error(y_train, y_pred_train)
            test_score = mean_absolute_percentage_error(y_test, y_pred_test)
        elif eval_metric == "MSE":
            train_score = mean_squared_error(y_train, y_pred_train)
            test_score = mean_squared_error(y_test, y_pred_test)
        
        return train_score, test_score

    def plot_results(original_x, y_test, y_pred, ob, x_label):
        sorted_indices = np.argsort(original_x)
        original_x_sorted = original_x.iloc[sorted_indices]
        y_test_sorted = np.array(y_test)[sorted_indices]
        y_pred_sorted = np.array(y_pred)[sorted_indices]

        fig = go.Figure()
        fig.add_trace(go.Scatter(x=original_x_sorted, y=y_test_sorted, mode='lines', name='å®Ÿéš›ã®å€¤', line=dict(color='blue')))
        fig.add_trace(go.Scatter(x=original_x_sorted, y=y_pred_sorted, mode='lines', name='äºˆæ¸¬å€¤', line=dict(color='red')))
        fig.update_layout(xaxis_title=x_label, yaxis_title=ob)
        st.plotly_chart(fig)

        fig = go.Figure()
        fig.add_trace(go.Bar(x=original_x_sorted, y=y_test_sorted, name='å®Ÿéš›ã®å€¤', marker=dict(color='blue')))
        fig.add_trace(go.Bar(x=original_x_sorted, y=y_pred_sorted, name='äºˆæ¸¬å€¤', marker=dict(color='red')))
        fig.update_layout(xaxis_title=x_label, yaxis_title=ob, barmode='group')
        st.plotly_chart(fig)

    if ml_menu == "é‡å›å¸°åˆ†æ":
        if st.button("å®Ÿè¡Œ"):
            lr = LinearRegression()
            df_ex, df_ob, original_ex = preprocess_data(df, ex, ob, encoding_type)

            if validation_method == "ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆ":
                X_train, X_test, y_train, y_test = train_test_split(df_ex, df_ob, test_size=test_size)
                lr.fit(X_train, y_train)
                train_score, test_score = evaluate_model(lr, X_train, X_test, y_train, y_test, eval_metric)
                st.write(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚³ã‚¢: {train_score}")
                st.write(f"ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score}")

                y_pred = lr.predict(X_test)
                plot_results(original_ex.loc[X_test.index, ex[0]], y_test, y_pred, ob, ex[0])

            elif validation_method == "äº¤å·®æ¤œè¨¼":
                scores = cross_val_score(lr, df_ex, df_ob, cv=5, scoring='r2')
                st.write(f"äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢ (R2): {scores.mean()}")

                lr.fit(df_ex, df_ob)
                y_pred = lr.predict(df_ex)
                plot_results(original_ex[ex[0]], df_ob, y_pred, ob, ex[0])

            elif validation_method == "k-fold":
                kf = KFold(n_splits=5)
                kf.get_n_splits(df_ex)
                scores = []
                y_test_all, y_pred_all = [], []
                for train_index, test_index in kf.split(df_ex):
                    X_train, X_test = df_ex.iloc[train_index], df_ex.iloc[test_index]
                    y_train, y_test = df_ob.iloc[train_index], df_ob.iloc[test_index]
                    lr.fit(X_train, y_train)
                    train_score, test_score = evaluate_model(lr, X_train, X_test, y_train, y_test, eval_metric)
                    scores.append(test_score)
                    y_test_all.extend(y_test)
                    y_pred_all.extend(lr.predict(X_test))
                st.write(f"k-foldã‚¹ã‚³ã‚¢ (å¹³å‡): {np.mean(scores)}")
                plot_results(original_ex.loc[df_ex.index, ex[0]], y_test_all, y_pred_all, ob, ex[0])

            joblib.dump(lr, model_filename)
            st.success(f"ãƒ¢ãƒ‡ãƒ«ãŒ{model_filename}ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            model_download_link = download_link(open(model_filename, "rb").read(), model_filename, 'ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
            st.markdown(model_download_link, unsafe_allow_html=True)

    elif ml_menu == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°åˆ†æ":
        if st.button("å®Ÿè¡Œ"):
            lr = LogisticRegression()
            df_ex, df_ob, original_ex = preprocess_data(df, ex, ob, encoding_type)

            if validation_method == "ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆ":
                X_train, X_test, y_train, y_test = train_test_split(df_ex, df_ob, test_size=test_size)
                lr.fit(X_train, y_train)
                train_score, test_score = evaluate_model(lr, X_train, X_test, y_train, y_test, eval_metric)
                st.write(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚³ã‚¢: {train_score}")
                st.write(f"ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score}")

                y_pred = lr.predict(X_test)
                plot_results(original_ex.loc[X_test.index, ex[0]], y_test, y_pred, ob, ex[0])

            elif validation_method == "äº¤å·®æ¤œè¨¼":
                scores = cross_val_score(lr, df_ex, df_ob, cv=5, scoring='accuracy')
                st.write(f"äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢ (Accuracy): {scores.mean()}")

                lr.fit(df_ex, df_ob)
                y_pred = lr.predict(df_ex)
                plot_results(original_ex[ex[0]], df_ob, y_pred, ob, ex[0])

            elif validation_method == "k-fold":
                kf = KFold(n_splits=5)
                kf.get_n_splits(df_ex)
                scores = []
                y_test_all, y_pred_all = [], []
                for train_index, test_index in kf.split(df_ex):
                    X_train, X_test = df_ex.iloc[train_index], df_ex.iloc[test_index]
                    y_train, y_test = df_ob.iloc[train_index], df_ob.iloc[test_index]
                    lr.fit(X_train, y_train)
                    train_score, test_score = evaluate_model(lr, X_train, X_test, y_train, y_test, eval_metric)
                    scores.append(test_score)
                    y_test_all.extend(y_test)
                    y_pred_all.extend(lr.predict(X_test))
                st.write(f"k-foldã‚¹ã‚³ã‚¢ (å¹³å‡): {np.mean(scores)}")
                plot_results(original_ex.loc[df_ex.index, ex[0]], y_test_all, y_pred_all, ob, ex[0])

            joblib.dump(lr, model_filename)
            st.success(f"ãƒ¢ãƒ‡ãƒ«ãŒ{model_filename}ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            model_download_link = download_link(open(model_filename, "rb").read(), model_filename, 'ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
            st.markdown(model_download_link, unsafe_allow_html=True)

    elif ml_menu == "LightGBM":
        if st.button("å®Ÿè¡Œ"):
            lgbm = lgb.LGBMRegressor()
            df_ex, df_ob, original_ex = preprocess_data(df, ex, ob, encoding_type)

            if validation_method == "ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆ":
                X_train, X_test, y_train, y_test = train_test_split(df_ex, df_ob, test_size=test_size)
                lgbm.fit(X_train, y_train)
                train_score, test_score = evaluate_model(lgbm, X_train, X_test, y_train, y_test, eval_metric)
                st.write(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚³ã‚¢: {train_score}")
                st.write(f"ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score}")

                y_pred = lgbm.predict(X_test)
                plot_results(original_ex.loc[X_test.index, ex[0]], y_test, y_pred, ob, ex[0])

            elif validation_method == "äº¤å·®æ¤œè¨¼":
                scores = cross_val_score(lgbm, df_ex, df_ob, cv=5, scoring='r2') 
                st.write(f"äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢ (R2): {scores.mean()}")

                lgbm.fit(df_ex, df_ob)
                y_pred = lgbm.predict(df_ex)
                plot_results(original_ex[ex[0]], df_ob, y_pred, ob, ex[0])

            elif validation_method == "k-fold":
                kf = KFold(n_splits=5)
                kf.get_n_splits(df_ex)
                scores = []
                y_test_all, y_pred_all = [], []
                for train_index, test_index in kf.split(df_ex):
                    X_train, X_test = df_ex.iloc[train_index], df_ex.iloc[test_index]
                    y_train, y_test = df_ob.iloc[train_index], df_ob.iloc[test_index]
                    lgbm.fit(X_train, y_train)
                    train_score, test_score = evaluate_model(lgbm, X_train, X_test, y_train, y_test, eval_metric)
                    scores.append(test_score)
                    y_test_all.extend(y_test)
                    y_pred_all.extend(lgbm.predict(X_test))
                st.write(f"k-foldã‚¹ã‚³ã‚¢ (å¹³å‡): {np.mean(scores)}")
                plot_results(original_ex.loc[df_ex.index, ex[0]], y_test_all, y_pred_all, ob, ex[0])

            joblib.dump(lgbm, model_filename)
            st.success(f"ãƒ¢ãƒ‡ãƒ«ãŒ{model_filename}ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            model_download_link = download_link(open(model_filename, "rb").read(), model_filename, 'ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
            st.markdown(model_download_link, unsafe_allow_html=True)

    elif ml_menu == "Catboost":
        if st.button("å®Ÿè¡Œ"):
            cb = CatBoostRegressor(verbose=0)
            df_ex, df_ob, original_ex = preprocess_data(df, ex, ob, encoding_type)

            if validation_method == "ãƒ›ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¦ãƒˆ":
                X_train, X_test, y_train, y_test = train_test_split(df_ex, df_ob, test_size=test_size)
                cb.fit(X_train, y_train)
                train_score, test_score = evaluate_model(cb, X_train, X_test, y_train, y_test, eval_metric)
                st.write(f"ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¹ã‚³ã‚¢: {train_score}")
                st.write(f"ãƒ†ã‚¹ãƒˆã‚¹ã‚³ã‚¢: {test_score}")

                y_pred = cb.predict(X_test)
                plot_results(original_ex.loc[X_test.index, ex[0]], y_test, y_pred, ob, ex[0])

            elif validation_method == "äº¤å·®æ¤œè¨¼":
                scores = cross_val_score(cb, df_ex, df_ob, cv=5, scoring='r2')
                st.write(f"äº¤å·®æ¤œè¨¼ã‚¹ã‚³ã‚¢ (R2): {scores.mean()}")

                cb.fit(df_ex, df_ob)
                y_pred = cb.predict(df_ex)
                plot_results(original_ex[ex[0]], df_ob, y_pred, ob, ex[0])

            elif validation_method == "k-fold":
                kf = KFold(n_splits=5)
                kf.get_n_splits(df_ex)
                scores = []
                y_test_all, y_pred_all = [], []
                for train_index, test_index in kf.split(df_ex):
                    X_train, X_test = df_ex.iloc[train_index], df_ex.iloc[test_index]
                    y_train, y_test = df_ob.iloc[train_index], df_ob.iloc[test_index]
                    cb.fit(X_train, y_train)
                    train_score, test_score = evaluate_model(cb, X_train, X_test, y_train, y_test, eval_metric)
                    scores.append(test_score)
                    y_test_all.extend(y_test)
                    y_pred_all.extend(cb.predict(X_test))
                st.write(f"k-foldã‚¹ã‚³ã‚¢ (å¹³å‡): {np.mean(scores)}")
                plot_results(original_ex.loc[df_ex.index, ex[0]], y_test_all, y_pred_all, ob, ex[0])

            joblib.dump(cb, model_filename)
            st.success(f"ãƒ¢ãƒ‡ãƒ«ãŒ{model_filename}ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
            model_download_link = download_link(open(model_filename, "rb").read(), model_filename, 'ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
            st.markdown(model_download_link, unsafe_allow_html=True)

st.sidebar.markdown("### å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦äºˆæ¸¬ã‚’è¡Œã†")
uploaded_model = st.sidebar.file_uploader("ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=["pkl"])
uploaded_data = st.sidebar.file_uploader("äºˆæ¸¬ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„", type=['csv', 'xlsx'])

if uploaded_model and uploaded_data:
    if uploaded_data.name.endswith('.csv'):
        df = pd.read_csv(uploaded_data)
    elif uploaded_data.name.endswith('.xlsx'):
        df = pd.read_excel(uploaded_data)

    df_columns = df.columns
    st.markdown("### ãƒ¢ãƒ‡ãƒªãƒ³ã‚°")
    ex = st.multiselect("èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰", df_columns, key="modeling_ex")
    ob = st.selectbox("ç›®çš„å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„", df_columns, key="modeling_ob")
    encoding_type = st.selectbox("ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦ãã ã•ã„", ["Label Encoding", "One-Hot Encoding"], key="encoding_type")
    
    if st.button("å®Ÿè¡Œ"):
        try:
            model = joblib.load(uploaded_model)
            df_ex, df_ob, original_ex = preprocess_data(df, ex, ob, encoding_type)

            y_pred = model.predict(df_ex)
            
            st.markdown("### äºˆæ¸¬çµæœ")
            x_axis = st.selectbox("Xè»¸ã«ä½¿ç”¨ã™ã‚‹èª¬æ˜å¤‰æ•°ã‚’é¸æŠã—ã¦ãã ã•ã„", ex, key="x_axis")
            
            sorted_indices = np.argsort(original_ex[x_axis])
            original_ex_sorted = original_ex.iloc[sorted_indices]
            df_ob_sorted = df_ob[sorted_indices]
            y_pred_sorted = y_pred[sorted_indices]
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(x=original_ex_sorted[x_axis], y=df_ob_sorted, mode='lines', name='å®Ÿéš›ã®å€¤', line=dict(color='blue')))
            fig.add_trace(go.Scatter(x=original_ex_sorted[x_axis], y=y_pred_sorted, mode='lines', name='äºˆæ¸¬å€¤', line=dict(color='red')))
            fig.update_layout(xaxis_title=x_axis, yaxis_title=ob)
            st.plotly_chart(fig)

            fig = go.Figure()
            fig.add_trace(go.Bar(x=original_ex_sorted[x_axis], y=df_ob_sorted, name='å®Ÿéš›ã®å€¤', marker=dict(color='blue')))
            fig.add_trace(go.Bar(x=original_ex_sorted[x_axis], y=y_pred_sorted, name='äºˆæ¸¬å€¤', marker=dict(color='red')))
            fig.update_layout(xaxis_title=x_axis, yaxis_title=ob, barmode='group')
            st.plotly_chart(fig)

            df_result = df.copy()
            df_result[f'{ob}_äºˆæ¸¬'] = y_pred
            tmp_download_link = download_link(df_result, 'ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬çµæœ.csv', 'äºˆæ¸¬çµæœã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰')
            st.markdown(tmp_download_link, unsafe_allow_html=True)
        except Exception as e:
            st.error(f"ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
